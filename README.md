# SeekUI: Predicting Visual Search Behavior on Graphical User Interfaces with a Reward-Augmented Vision Language Model

<div align="center">

*The two-stage SeekUI framework: Instruction Tuning stage and Reinforcement Learning stage.*

[![CHI 2026](https://img.shields.io/badge/CHI-2026-blue)](https://chi2026.acm.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)

<!-- **Zixin Guo**$^{*1}$, **Yue Jiang**$^{*2}$, **Luis A. Leiva**$^{3}$, **Antti Oulasvirta**$^{1}$ -->

<!-- **Published at CHI 2026** -->

</div>

## ğŸ“¢ News
* **[Coming Soon]** We are currently organizing the code and checkpoints. They will be released shortly. Please star â­ this repo to get notifications!
* **[2026-01-15]** The paper is accepted with Minor Revision to **CHI 2026**! ğŸ‰

## ğŸ  Abstract
This repository contains the official implementation of the paper **"SeekUI: Predicting Visual Search Behavior on Graphical User Interfaces with a Reward-Augmented Vision Language Model"**.



## ğŸš€ TODO List
- [ ] Release the paper.
- [ ] Release the training and inference code.
- [ ] Release the pre-trained checkpoints and the processed data.

## ğŸ“– Citation
If you find our work or this repository useful, please consider citing our paper:
